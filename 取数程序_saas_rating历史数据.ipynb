{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入库与初始化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "import pymysql\n",
    "import sqlite3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date\n",
    "\n",
    "from data_logger import setup_logger\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "logger = setup_logger()\n",
    "\n",
    "\n",
    "def execute_with_error_handling(func, query_config, func_name):    #取数报错日志\n",
    "    try:\n",
    "        return func(query_config)\n",
    "    except Exception as e:\n",
    "        logger.info(f\"取数函数 {func_name} 运行时发生错误：{e}\")\n",
    "\n",
    "def empty_folder(folder_path):   #清空文件夹\n",
    "    \"\"\"\n",
    "    清空指定文件夹的内容（包括子文件夹及其内容），但保留该文件夹本身。\n",
    "    \n",
    "    :param folder_path: 要清空的文件夹路径\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        logger.info(f\"文件夹 {folder_path} 不存在\")\n",
    "        return\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder_path, topdown=False):\n",
    "        # 删除所有文件\n",
    "        for name in files:\n",
    "            file_path = os.path.join(root, name)\n",
    "            try:\n",
    "                os.remove(file_path)  # 删除文件\n",
    "            except Exception as e:\n",
    "                logger.info(f'Failed to delete file {file_path}. Reason: {e}')\n",
    "        \n",
    "        # 删除所有子文件夹\n",
    "        for name in dirs:\n",
    "            dir_path = os.path.join(root, name)\n",
    "            try:\n",
    "                os.rmdir(dir_path)  # 删除空目录\n",
    "            except Exception as e:\n",
    "                logger.info(f'Failed to delete directory {dir_path}. Reason: {e}')\n",
    "\n",
    "def insert_data_without_duplicates(df, table_name):\n",
    "    engine = create_engine('sqlite:///result/rating_db.db')\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        transaction = connection.begin()\n",
    "        for idx, row in df.iterrows():\n",
    "            columns = ', '.join(df.columns)\n",
    "            placeholders = ', '.join([':' + str(i) for i in range(len(df.columns))])\n",
    "            values = {str(i): value for i, value in enumerate(row)}\n",
    "            insert_stmt = text(f\"\"\"\n",
    "                INSERT OR IGNORE INTO {table_name} ({columns})\n",
    "                VALUES ({placeholders})\n",
    "            \"\"\")\n",
    "            try:\n",
    "                connection.execute(insert_stmt, values)\n",
    "            except Exception as e:\n",
    "                logger.info(f\"Error inserting row {row}: {e}\")\n",
    "                break\n",
    "        transaction.commit()\n",
    "    logger.info(table_name+'入库')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取数程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取数程序\n",
    "\n",
    "def get_market_value(config):\n",
    "    engine_istock = config[\"istock_conn\"]\n",
    "    start_date = config[\"start_date\"]\n",
    "    end_date = config[\"end_date\"]      ###此处的sql中的open_price时收盘价而非真正的open_price,未作该是因为防止报错\n",
    "    sql_quote_query = f\"\"\"\n",
    "    SELECT \n",
    "    td_date,\n",
    "    sec_code,\n",
    "    sec_short_name,\n",
    "    pre_close * (1 + COALESCE(chg_ratio, 0) / 100) AS open_price     \n",
    "    FROM \n",
    "    shsz_stock_daily_quotation\n",
    "    WHERE \n",
    "    td_date BETWEEN DATE_SUB('{start_date}', INTERVAL 90 DAY) AND '{end_date}'\n",
    "    AND sec_category = 'A股';\n",
    "    \"\"\"\n",
    "    price_df=pd.read_sql(sql_quote_query,engine_istock)  #读取价格数据\n",
    "\n",
    "\n",
    "    share_query = f'''SELECT css.publish_date,sbi.sec_code,css.float_shares\n",
    "        FROM corp_share_structure css \n",
    "        JOIN sec_basic_info sbi ON css.corp_code=sbi.issue_org_id\n",
    "        WHERE sbi.sec_type='A股'; '''\n",
    "    share_df=pd.read_sql(share_query,engine_istock)    #读取流通股本数据\n",
    "    share_df['publish_date']=pd.to_datetime(share_df['publish_date'])\n",
    "\n",
    "    def share_select(group,start_date):\n",
    "        before_3_month = datetime.strptime(start_date, \"%Y-%m-%d\") -timedelta(days=90)\n",
    "        if before_3_month>=group['publish_date'].max():\n",
    "            if len(group.loc[group['publish_date']==group['publish_date'].max()])>1:\n",
    "                return group.loc[group['publish_date']==group['publish_date'].max()].tail(1)\n",
    "            else:\n",
    "                return group.loc[group['publish_date']==group['publish_date'].max()]\n",
    "        else:\n",
    "            group = group.loc[group['publish_date']>=group.loc[group['publish_date']<before_3_month]['publish_date'].max()]\n",
    "            return group.groupby('publish_date').apply(lambda x:x.tail(1)).reset_index(drop=True)\n",
    "        \n",
    "    def add_float_shares(group,share_df):\n",
    "        try:\n",
    "            if len(share_df.loc[share_df['sec_code']==group['sec_code'].unique()[0]])==1:\n",
    "                group['float_shares']=share_df.loc[share_df['sec_code']==group['sec_code'].unique()[0]]['float_shares'].values[0]\n",
    "            else:\n",
    "                def update_float_shares(row,share_info):\n",
    "                    a=share_info.loc[share_info['publish_date']<=row['td_date']]\n",
    "                    a=a.loc[a['publish_date']==a['publish_date'].max()]['float_shares'].values[0]\n",
    "                    return a\n",
    "                stock_info=share_df.loc[share_df['sec_code']==group['sec_code'].unique()[0]]\n",
    "                group['float_shares']=group.apply(lambda row:update_float_shares(row,stock_info),axis=1)\n",
    "            return group\n",
    "        except:\n",
    "            print(group['sec_code'].unique()[0])\n",
    "            print(share_df.head(5))\n",
    "\n",
    "    share_df=share_df.groupby('sec_code').apply(share_select,start_date=start_date).reset_index(drop=True)\n",
    "    print(1)\n",
    "    market_value_df=price_df.groupby('sec_code').apply(add_float_shares,share_df=share_df).reset_index(drop=True)\n",
    "\n",
    "    market_value_df['float_market_value']=market_value_df['float_shares']*market_value_df['open_price']  # 计算流通市值\n",
    "    market_value_df.sort_values(by=['sec_code', 'td_date'], inplace=True)\n",
    "    market_value_df.set_index('td_date', inplace=True)\n",
    "    # 对每个 'sec_code' 分别计算滚动平均值\n",
    "    market_value_df['rolling_avg_float_market_value'] = market_value_df.groupby('sec_code')['float_market_value'].transform(lambda x: x.rolling(window='90D').mean())\n",
    "    market_value_df.reset_index(inplace=True)\n",
    "    market_value_df=market_value_df.loc[market_value_df['td_date']>=start_date]\n",
    "    market_value_df=market_value_df[['td_date','sec_code','sec_short_name','rolling_avg_float_market_value']]    # 输出流通市值平均dataframe\n",
    "    market_value_df['td_date'] = market_value_df['td_date'].dt.strftime('%Y-%m-%d')\n",
    "    market_value_df.columns=['trade_date','stock_code','sec_short_name','rolling_avg_float_market_value']\n",
    "    market_value_df.to_csv('temp_model_backtesting/market_value.csv',index=False) # 输出流通市值平均dataframe\n",
    "    return logger.info('流通市值计算完成,临时存入temp_model_backtesting/market_value.csv')\n",
    "\n",
    "def get_goodwill_ratio(config):    # 获取商誉函数\n",
    "        engine_istock = config[\"istock_conn\"]\n",
    "        start_date = config[\"start_date\"]\n",
    "        end_date = config[\"end_date\"]\n",
    "        sql_goodwill_ratio = f\"\"\"\n",
    "                SELECT stock_code AS stock_code, td AS trade_date, PROFITABILITY_4 AS goodwill_ratio\n",
    "                FROM indicator\n",
    "                WHERE td BETWEEN '{start_date}' AND '{end_date}'\n",
    "                \"\"\"\n",
    "        goodwill_ratio_df = pd.read_sql(sql_goodwill_ratio, engine_istock)\n",
    "        goodwill_ratio_df['stock_code'] = goodwill_ratio_df['stock_code'].str[:6]\n",
    "        goodwill_ratio_df['goodwill_ratio'].fillna(0, inplace=True)\n",
    "        goodwill_ratio_df['stock_code']=goodwill_ratio_df['stock_code'].astype(str)\n",
    "        goodwill_ratio_df.to_csv(\"temp_model_backtesting/goodwill_ratio.csv\", index=False)\n",
    "        del goodwill_ratio_df\n",
    "        return  logger.info(\"商誉占比计算完毕,临时存入temp_model_backtesting/goodwill_ratio.csv\")\n",
    "\n",
    "def get_trans_amt(config):\n",
    "        engine_istock = config[\"istock_conn\"]\n",
    "        start_date = config[\"start_date\"]\n",
    "        end_date =  config[\"end_date\"]\n",
    "\n",
    "        sql_trans_amt = f\"\"\"\n",
    "                        SELECT stock_code  , td AS trade_date, SPJ_001 AS trans_amt,CJL_001 AS trans_vol\n",
    "                        FROM evidence_daily\n",
    "                        WHERE td BETWEEN DATE_SUB('{start_date}', INTERVAL 90 DAY) AND '{end_date}'\n",
    "                        \"\"\"\n",
    "        df_trans_amt = pd.read_sql(sql_trans_amt, engine_istock)\n",
    "        df_trans_amt['trans_amt']=df_trans_amt['trans_amt']*df_trans_amt['trans_vol']    #计算成交额\n",
    "        # 确保日期是datetime格式，并仅保留年月日部分\n",
    "        df_trans_amt['trade_date'] = pd.to_datetime(df_trans_amt['trade_date'])\n",
    "        df_trans_amt.set_index('trade_date', inplace=True)\n",
    "        # 计算每个股票的交易额的滚动平均值\n",
    "        df_trans_amt['rolling_avg_trans_amt'] = df_trans_amt.groupby('stock_code')['trans_amt'].transform(lambda x: x.rolling(window='90D').mean())\n",
    "        df_trans_amt.reset_index(inplace=True)\n",
    "        df_trans_amt=df_trans_amt.loc[df_trans_amt['trade_date']>=start_date]\n",
    "        df_trans_amt['td_date'] = df_trans_amt['trade_date'].dt.strftime('%Y-%m-%d')\n",
    "        df_trans_amt['stock_code'] = df_trans_amt['stock_code'].str[:6]\n",
    "        df_trans_amt=df_trans_amt[['trade_date','stock_code','rolling_avg_trans_amt']]\n",
    "        df_trans_amt['stock_code']=df_trans_amt['stock_code'].astype(str)\n",
    "        df_trans_amt=df_trans_amt[['stock_code','trade_date','rolling_avg_trans_amt']]\n",
    "        df_trans_amt.to_csv('temp_model_backtesting/trans_amt.csv',index=False)\n",
    "        del df_trans_amt\n",
    "        return logger.info('日均交易额计算完毕,临时存入temp_model_backtesting/trans_amt.csv')\n",
    "\n",
    "def convert_percentage_to_float(series):     ##数据处理函数，用于get_dicount_rate的字符串字段\n",
    "    def convert_value(value):\n",
    "        if isinstance(value, str) and value.endswith('%'):\n",
    "            return float(value.rstrip('%')) / 100.0\n",
    "        elif isinstance(value, str):\n",
    "            return float(value)\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected value type: {type(value)}\") \n",
    "    return series.apply(convert_value)\n",
    "\n",
    "def get_discount_rate(config):     #同业折算率孰低值获取\n",
    "    engine_istock = config[\"istock_conn\"]\n",
    "    start_date = config[\"start_date\"]\n",
    "    end_date = config[\"end_date\"]\n",
    "\n",
    "    # 将 start_date 转换为日期格式\n",
    "    start_date_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    comparison_date = datetime(2024, 10, 9)\n",
    "\n",
    "    # 判断 start_date 是否早于 2024-10-09\n",
    "    if start_date_date < comparison_date:\n",
    "        # 创建一个空 DataFrame 并保存为 CSV 文件\n",
    "        df_empty = pd.DataFrame(columns=['trade_date', 'stock_code', 'discount_rate'])\n",
    "        df_empty.to_csv('temp_model_backtesting/discount_rate.csv', index=False)\n",
    "        logger.info(\"由于开始日期早于2024-10-09,已生成空CSV文件\")\n",
    "    else:\n",
    "        sql_discount_rate = f\"\"\"\n",
    "        SELECT m.broker_name, m.stock_code , m.stock_name, m.tra_date AS trade_date, m.discount_rate\n",
    "            FROM margin_trading_records m\n",
    "            WHERE \n",
    "                m.tra_date BETWEEN '{start_date}' AND '{end_date}'\n",
    "                AND m.broker_name IN ('中信证券', '中信建投', '招商证券', '广发证券', '平安证券', '华泰证券', '国信证券', '国泰君安')\n",
    "                AND m.discount_rate IS NOT NULL\n",
    "                AND m.concentration REGEXP '^[^[:space:]]+$'\n",
    "            \"\"\"\n",
    "        # 从数据库中读取数据\n",
    "        df_discount_rate = pd.read_sql(sql_discount_rate, engine_istock)\n",
    "        df_discount_rate['trade_date'] = pd.to_datetime(df_discount_rate['trade_date'])\n",
    "\n",
    "        # 假设 convert_percentage_to_float 是已经定义好的函数\n",
    "        df_discount_rate['discount_rate'] = convert_percentage_to_float(df_discount_rate['discount_rate'])\n",
    "\n",
    "        df_discount_rate = df_discount_rate.groupby(['trade_date', 'stock_code']).agg({\n",
    "            'stock_name': 'first',\n",
    "            'discount_rate': 'min'}).reset_index()   #取同业最低值\n",
    "        df_discount_rate = df_discount_rate[['trade_date','stock_code','discount_rate']]\n",
    "        df_discount_rate['trade_date'] = df_discount_rate['trade_date'].dt.strftime('%Y-%m-%d')\n",
    "        df_discount_rate['stock_code'] = df_discount_rate['stock_code'].astype(str) \n",
    "\n",
    "        df_discount_rate.to_csv('temp_model_backtesting/discount_rate.csv', index=False)\n",
    "        del df_discount_rate\n",
    "        logger.info('孰低折算率已经获取完毕,临时存入temp_model_backtesting/discount_rate.csv')\n",
    "\n",
    "def get_collateral_ratio(config):     #抵押比例获取函数\n",
    "        engine_istock = config[\"istock_conn\"]\n",
    "        start_date = config[\"start_date\"]\n",
    "        end_date =  config[\"end_date\"]\n",
    "\n",
    "        sql_collateral_ratio = f\"\"\"SELECT mcr.stock_code AS sec_code, mcr.date AS trade_date, mcr.ratio AS collateral_ratio, mcr.stock_name AS sec_short_name_cn\n",
    "                FROM market_collateral_records mcr \n",
    "                WHERE mcr.date >= '{start_date}' AND mcr.date <= '{end_date}';\n",
    "                \"\"\"\n",
    "        df_collateral_ratio = pd.read_sql(sql_collateral_ratio, engine_istock)\n",
    "        df_collateral_ratio['trade_date']=end_date\n",
    "\n",
    "                # 将 sec_code 映射到 sec_basic_info 表中的 thscode，命名为 stock_code\n",
    "        sql_sec_mapping = \"\"\"\n",
    "                SELECT sbi.sec_code, sbi.thscode AS stock_code, sbi.sec_short_name_cn\n",
    "                FROM sec_basic_info sbi\n",
    "                \"\"\"\n",
    "        df_sec_mapping = pd.read_sql(sql_sec_mapping, engine_istock)\n",
    "\n",
    "                # 合并映射表，将 sec_code 映射为 stock_code\n",
    "        df_collateral_ratio = df_collateral_ratio.merge(df_sec_mapping, on=['sec_code','sec_short_name_cn'], how='inner')\n",
    "        df_collateral_ratio = df_collateral_ratio[['sec_code', 'trade_date', 'collateral_ratio']]\n",
    "        df_collateral_ratio.columns = ['stock_code', 'trade_date', 'collateral_ratio']\n",
    "        df_collateral_ratio['trade_date']=df_collateral_ratio['trade_date'].astype(str)\n",
    "        df_collateral_ratio['stock_code']=df_collateral_ratio['stock_code'].astype(str)\n",
    "        df_collateral_ratio.to_csv('temp_model_backtesting\\collateral_ratio.csv',index=False)\n",
    "        del df_collateral_ratio\n",
    "        del df_sec_mapping\n",
    "        return logger.info('单一担保物质押比例已经获取完毕,临时存入temp_model_backtesting/collateral_ratio.csv')\n",
    "\n",
    "def get_delloitte_rating(config):     #德勤评级获取函数(目前弃用)\n",
    "        engine_istock = config[\"istock_conn\"]\n",
    "        start_date = config[\"start_date\"]\n",
    "        end_date =  config[\"end_date\"]\n",
    "\n",
    "        sql_deloitte_rating = f\"\"\"\n",
    "                SELECT stock_code AS stock_code, td AS trade_date, five_class_result_adj\n",
    "                FROM model_st\n",
    "                WHERE td BETWEEN '{start_date}' AND '{end_date}'\n",
    "                \"\"\"\n",
    "\n",
    "        df_deloitte_rating = pd.read_sql(sql_deloitte_rating, engine_istock)    #获取德勤评级\n",
    "        df_deloitte_rating['stock_code'] = df_deloitte_rating['stock_code'].str[:6]\n",
    "        df_deloitte_rating['stock_code'] = df_deloitte_rating['stock_code'].astype(str)\n",
    "        df_deloitte_rating['trade_date'] = df_deloitte_rating['trade_date'].astype(str)\n",
    "        df_deloitte_rating.to_csv('temp_model_backtesting/deloitte_rating.csv', index=False)\n",
    "        del df_deloitte_rating\n",
    "        return logger.info(\"德勤评级数据获取成功,临时保存在 temp_model_backtesting/deloitte_rating.csv\")\n",
    "\n",
    "def get_deloitte_rating_1(config):\n",
    "    # 获取德勤评级数据(smooth_score)\n",
    "    engine_istock = config[\"istock_conn\"]\n",
    "    start_date = config[\"start_date\"]\n",
    "    end_date = config[\"end_date\"]\n",
    "\n",
    "    sql_deloitte_rating = f\"\"\"SELECT stock_code AS stock_code, td AS trade_date, smooth_score AS smooth_score \n",
    "    FROM model_st WHERE td BETWEEN '{start_date}' AND '{end_date}'\n",
    "    \"\"\"\n",
    "\n",
    "    df_deloitte_rating = pd.read_sql(sql_deloitte_rating, engine_istock)  # 获取smooth_score\n",
    "    df_deloitte_rating['stock_code'] = df_deloitte_rating['stock_code'].str[:6]\n",
    "    df_deloitte_rating['stock_code'] = df_deloitte_rating['stock_code'].astype(str)\n",
    "    df_deloitte_rating['trade_date'] = pd.to_datetime(df_deloitte_rating['trade_date'])\n",
    "\n",
    "    # 按 trade_date 分组并计算每日的百分位数阈值\n",
    "    percentiles = [0.95, 0.85, 0.30, 0.07]      ###   设置百分位数阈值!!!    ###\n",
    "\n",
    "    def calculate_daily_thresholds(group):\n",
    "        thresholds = group['smooth_score'].quantile(percentiles).tolist()\n",
    "        return thresholds\n",
    "\n",
    "    daily_thresholds = df_deloitte_rating.groupby('trade_date').apply(calculate_daily_thresholds)\n",
    "\n",
    "    # 定义分类函数\n",
    "    def classify(score, date):\n",
    "        thresholds = daily_thresholds[date]\n",
    "        if score >= thresholds[0]:\n",
    "            return 'A'\n",
    "        elif score >= thresholds[1]:\n",
    "            return 'B'\n",
    "        elif score >= thresholds[2]:\n",
    "            return 'C'\n",
    "        elif score >= thresholds[3]:\n",
    "            return 'D'\n",
    "        else:\n",
    "            return 'E'\n",
    "\n",
    "    # 应用分类函数\n",
    "    df_deloitte_rating['five_class_result_adj'] = df_deloitte_rating.apply(\n",
    "        lambda row: classify(row['smooth_score'], row['trade_date']), axis=1\n",
    "    )\n",
    "\n",
    "    # 选择需要的列\n",
    "    df_deloitte_rating = df_deloitte_rating[['stock_code', 'trade_date', 'five_class_result_adj']]\n",
    "    # 保存到CSV文件\n",
    "    df_deloitte_rating.to_csv('temp_model_backtesting/deloitte_rating_1.csv', index=False)\n",
    "    \n",
    "    del df_deloitte_rating\n",
    "    return logger.info(\"德勤评级数据_1获取成功,临时保存在 temp_model_backtesting/deloitte_rating_1.csv\")\n",
    "\n",
    "def get_stock_info(config):       #股票基本信息获取（基础股票池）\n",
    "    sql='''SELECT thscode AS stock_code,listed_board_name ,listed_date ,td_mkt  ,st_issuance ,index_name FROM stock_info;'''\n",
    "    df = pd.read_sql(sql,config[\"istock_conn\"])\n",
    "\n",
    "    df['stock_code']=df['stock_code'].astype(str)\n",
    "    df['listed_date']=df['listed_date'].astype(str)\n",
    "    ################当前版本，此处暂时不用（无需index_name 和 index_name_1）###################\n",
    "    x=pd.read_excel(r'password_attention\\中证800成分股数据.xlsx')\n",
    "    xp=x['\\t股票代码'].str[1:10].values\n",
    "    df['index_name_1'] = df['stock_code'].apply(lambda x: '中证800' if x in xp else None)   #填入中证800字段\n",
    "    #########################################################################################\n",
    "    df['stock_code'] = df['stock_code'].str[:6]\n",
    "    #df['st_issuance'].fillna('注册制',inplace=True)\n",
    "    df.to_csv('temp_model_backtesting/stock_info.csv',index=False)\n",
    "    del df\n",
    "    return logger.info('获取最新stock_info成功,临时存在temp_model_backtesting/stock_info.csv')\n",
    "\n",
    "def wanlian_data_merge():    #合并函数\n",
    "    directory_path='temp_model_backtesting'\n",
    "    try:    \n",
    "        all_items = os.listdir(directory_path)\n",
    "        files = [item for item in all_items if os.path.isfile(os.path.join(directory_path, item))]\n",
    "    except Exception as e:\n",
    "        logger.info(f\"读取临时文件名发生了一个错误：{e}\")\n",
    "\n",
    "    wanlian_df=None\n",
    "    try:\n",
    "        trans_amt=pd.read_csv(directory_path+'/'+files[6],dtype={'stock_code': str, 'trade_date': str})\n",
    "        market_value=pd.read_csv(directory_path+'/'+files[4],dtype={'stock_code': str, 'trade_date': str})\n",
    "        wanlian_df=pd.merge(trans_amt,market_value,on=['trade_date','stock_code'],how='left')\n",
    "        del trans_amt\n",
    "        del market_value\n",
    "        collateral_ratio=pd.read_csv(directory_path+'/'+files[0],dtype={'stock_code': str, 'trade_date': str})\n",
    "        wanlian_df=pd.merge(wanlian_df,collateral_ratio,on=['trade_date','stock_code'],how='left')\n",
    "        del collateral_ratio\n",
    "        delloitte_rating=pd.read_csv(directory_path+'/'+files[1],dtype={'stock_code': str, 'trade_date': str})\n",
    "        wanlian_df=pd.merge(wanlian_df,delloitte_rating,on=['trade_date','stock_code'],how='left')\n",
    "        del delloitte_rating\n",
    "        discount_rate=pd.read_csv(directory_path+'/'+files[2],dtype={'stock_code': str, 'trade_date': str})\n",
    "        if len(discount_rate)>2:\n",
    "            wanlian_df=pd.merge(wanlian_df,discount_rate,on=['trade_date','stock_code'],how='left')\n",
    "            del discount_rate\n",
    "        else:\n",
    "            logger.info('############## discount_rate数据为空,忽略此条件 ##############')\n",
    "        goodwill_ratio=pd.read_csv(directory_path+'/'+files[3],dtype={'stock_code': str, 'trade_date': str})\n",
    "        wanlian_df=pd.merge(wanlian_df,goodwill_ratio,on=['trade_date','stock_code'],how='left')\n",
    "        del goodwill_ratio\n",
    "        stock_info=pd.read_csv(directory_path+'/'+files[5],dtype={'stock_code': str, 'trade_date': str})\n",
    "        wanlian_df=pd.merge(wanlian_df,stock_info,on=['stock_code'],how='left')\n",
    "        del stock_info\n",
    "        wanlian_df['rolling_avg_trans_amt_rank']=wanlian_df.groupby('trade_date')['rolling_avg_trans_amt'].rank(pct=True, ascending=False)\n",
    "        wanlian_df['rolling_avg_float_market_value_rank']=wanlian_df.groupby('trade_date')['rolling_avg_float_market_value'].rank(pct=True, ascending=False)\n",
    "        logger.info('万联数据已准备好！')\n",
    "        return wanlian_df\n",
    "    except Exception as e:\n",
    "        logger.info(f\"合并表时发生了一个错误：{e}\")\n",
    "\n",
    "def get_saas_data(query_config):\n",
    "    # 内置functions_to_execute列表\n",
    "    functions_to_execute = [\n",
    "        (get_market_value, \"get_market_value\"),\n",
    "        (get_goodwill_ratio, \"get_goodwill_ratio\"),\n",
    "        (get_trans_amt, \"get_trans_amt\"),\n",
    "        (get_discount_rate, \"get_discount_rate\"),\n",
    "        (get_collateral_ratio, \"get_collateral_ratio\"),\n",
    "        #(get_delloitte_rating, \"get_delloitte_rating\"),  # 注释掉的示例行\n",
    "        (get_deloitte_rating_1, \"get_deloitte_rating_1\"),\n",
    "        (get_stock_info, \"get_stock_info\")\n",
    "    ]\n",
    "    # 执行所有取数函数并处理可能的异常\n",
    "    for func, name in functions_to_execute:\n",
    "        execute_with_error_handling(func, query_config, name)\n",
    "\n",
    "    # 合并所有取数结果为一个wanlian_df\n",
    "    wanlian_df = wanlian_data_merge()\n",
    "\n",
    "    wanlian_df_test = wanlian_df.copy()\n",
    "    insert_data_without_duplicates(wanlian_df, 'saas_indicator')\n",
    "    del wanlian_df\n",
    "    \n",
    "    wanlian_df_test['index_name'].fillna(\"\", inplace=True)\n",
    "    \n",
    "    default_collateral_ratio = 0\n",
    "    wanlian_df_test['collateral_ratio'] = wanlian_df_test.groupby('stock_code')['collateral_ratio']\\\n",
    "        .transform(lambda x: x.fillna(x.mean()) if x.notnull().any() else default_collateral_ratio)\n",
    "    \n",
    "    if 'discount_rate' in wanlian_df_test.columns:\n",
    "        default_discount_rate = 0.8\n",
    "        wanlian_df_test['discount_rate'] = wanlian_df_test.groupby('stock_code')['discount_rate']\\\n",
    "                .transform(lambda x: x.fillna(x.mean()) if x.notnull().any() else default_discount_rate)\n",
    "    \n",
    "    wanlian_df_test['trade_date'] = pd.to_datetime(wanlian_df_test['trade_date'], errors='coerce')\n",
    "    wanlian_df_test['listed_date'] = pd.to_datetime(wanlian_df_test['listed_date'], errors='coerce')\n",
    "    wanlian_df_test = wanlian_df_test.dropna(subset=['five_class_result_adj'])\n",
    "    wanlian_df_test = wanlian_df_test.dropna(subset=['rolling_avg_float_market_value_rank'])\n",
    "    \n",
    "    logger.info('开始万联规则判断，生成万联分布')\n",
    "    if 'discount_rate' in wanlian_df_test.columns:\n",
    "        wanlian_df_test[\"wanlian_rating\"] = wanlian_df_test.apply(wanlian_grade_judge_basedeloitte, axis=1)\n",
    "    else:\n",
    "        wanlian_df_test[\"wanlian_rating\"] = wanlian_df_test.apply(wanlian_grade_judge_basedeloitte_early, axis=1)\n",
    "    \n",
    "    logger.info('万联评级生成完毕！')\n",
    "    \n",
    "    wanlian_df_test = wanlian_df_test[['stock_code', 'trade_date', 'five_class_result_adj', 'wanlian_rating']]\n",
    "    wanlian_df_test['trade_date'] = wanlian_df_test['trade_date'].dt.strftime('%Y-%m-%d')\n",
    "    insert_data_without_duplicates(wanlian_df_test, 'saas_rating')\n",
    "    empty_folder('temp_model_backtesting')\n",
    "    \n",
    "    logger.info('万联评级保存在result文件夹rating_db.db下,程序运行完毕!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "万联评级判断程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主程序运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################初始化查询配置,此处修改时间区间#####################\n",
    "query_config = init(start_date=\"2024-02-06\", end_date=\"2024-10-08\")      \n",
    "#######################################################################\n",
    "\n",
    "functions_to_execute = [(get_market_value, \"get_market_value\"),\n",
    "    (get_goodwill_ratio, \"get_goodwill_ratio\"),\n",
    "    (get_trans_amt, \"get_trans_amt\"),\n",
    "    (get_discount_rate, \"get_discount_rate\"),\n",
    "    (get_collateral_ratio, \"get_collateral_ratio\"),\n",
    "    #(get_delloitte_rating, \"get_delloitte_rating\"),\n",
    "    (get_deloitte_rating_1, \"get_deloitte_rating_1\"),\n",
    "    (get_stock_info, \"get_stock_info\")]\n",
    "\n",
    "# 执行所有取数函数并处理可能的异常\n",
    "for func, name in functions_to_execute:\n",
    "    execute_with_error_handling(func, query_config, name)\n",
    "\n",
    "# 合并所有取数结果为一个wanlian_df\n",
    "wanlian_df=wanlian_data_merge()\n",
    "\n",
    "wanlian_df_test=wanlian_df.copy()\n",
    "#wanlian_df.to_csv('result/'+query_config['start_date']+'-'+query_config['end_date']+\"-wanlian_data_V2_st.csv\",index=False)\n",
    "insert_data_without_duplicates(wanlian_df, 'saas_indicator')\n",
    "del wanlian_df\n",
    "wanlian_df_test['index_name'].fillna(\"\",inplace=True)\n",
    "\n",
    "default_collateral_ratio = 0\n",
    "wanlian_df_test['collateral_ratio'] = wanlian_df_test.groupby('stock_code')['collateral_ratio']\\\n",
    "    .transform(lambda x: x.fillna(x.mean()) if x.notnull().any() else default_collateral_ratio)\n",
    "if 'discount_rate' in wanlian_df_test.columns:\n",
    "    default_discount_rate = 0.8\n",
    "    wanlian_df_test['discount_rate'] = wanlian_df_test.groupby('stock_code')['discount_rate']\\\n",
    "            .transform(lambda x: x.fillna(x.mean()) if x.notnull().any() else default_discount_rate)\n",
    "else:\n",
    "    pass\n",
    "wanlian_df_test['trade_date'] = pd.to_datetime(wanlian_df_test['trade_date'], errors='coerce')\n",
    "wanlian_df_test['listed_date'] = pd.to_datetime(wanlian_df_test['listed_date'], errors='coerce')\n",
    "wanlian_df_test = wanlian_df_test.dropna(subset=['five_class_result_adj'])\n",
    "wanlian_df_test = wanlian_df_test.dropna(subset=['rolling_avg_float_market_value_rank'])\n",
    "logger.info('开始万联规则判断，生成万联分布')\n",
    "#wanlian_df_test[\"wanlian_rating\"] = wanlian_df_test.apply(wanlian_grade_judge, axis=1)\n",
    "if 'discount_rate' in wanlian_df_test.columns:\n",
    "    wanlian_df_test[\"wanlian_rating\"] = wanlian_df_test.apply(wanlian_grade_judge_basedeloitte, axis=1)\n",
    "else:\n",
    "    wanlian_df_test[\"wanlian_rating\"] = wanlian_df_test.apply(wanlian_grade_judge_basedeloitte_early, axis=1)\n",
    "logger.info('万联评级生成完毕！')\n",
    "wanlian_df_test=wanlian_df_test[['stock_code','trade_date','five_class_result_adj','wanlian_rating']]\n",
    "#wanlian_df_test.to_csv('result/'+query_config['start_date']+'-'+query_config['end_date']+\"-wanlian_rating_data_V2_st.csv\",index=False)\n",
    "wanlian_df_test['trade_date'] = wanlian_df_test['trade_date'].dt.strftime('%Y-%m-%d')\n",
    "insert_data_without_duplicates(wanlian_df_test, 'saas_rating')\n",
    "empty_folder('temp_model_backtesting')\n",
    "logger.info('万联评级保存在result文件夹rating_db.db下,程序运行完毕!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
